{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI6MfNCdV2av"
      },
      "source": [
        "## Twitter Tweets Sentiment Analysis for Natural Language Processing NLP Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIckhmUQWvMV"
      },
      "source": [
        "### 1. DATASET DESCRIPTION:\n",
        "\n",
        "Dataset: Twitter Tweets Sentiment Dataset by M. Yasser H. on Kaggle\n",
        "Kaggle\n",
        "+2\n",
        "Kaggle\n",
        "+2\n",
        "\n",
        "Description: The dataset contains tweets labeled for sentiment (positive, neutral, negative).\n",
        "\n",
        "According to one source, it has 27,481 rows (i.e., tweets) labeled across those three sentiment classes.\n",
        "arXiv\n",
        "\n",
        "Columns (features) include (at least): textID (unique id), text (tweet content), sentiment (label).\n",
        "IT in Industry\n",
        "\n",
        "According to the “Applying NLP and Machine Learning for Sentiment …” paper, sentiment values are: 0 = negative, 2 = neutral, 4 = positive.\n",
        "IT in Industry\n",
        "+1\n",
        "\n",
        "The dataset size is quite moderate (file size is ~1 MB) according to the Kaggle page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQNZlrj2iYUx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnCIGOu0qTKh"
      },
      "source": [
        "### 2. Dataset Selection from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj90v1TaV1m6"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "!pip install kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"yasserh/twitter-tweets-sentiment-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqtKo7WqfU33"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Show files in the dataset folder\n",
        "print(\"Files inside the dataset folder:\")\n",
        "print(os.listdir(path))\n",
        "\n",
        "# Correct file path\n",
        "file_path = os.path.join(path, \"Tweets.csv\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"\\nFIRST 5 ROWS OF THE DATASET \")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqT6kbYqfgBt"
      },
      "outputs": [],
      "source": [
        "#Data Description\n",
        "print(\"\\n DATASET DESCRIPTION \")\n",
        "\n",
        "print(\"Number of samples:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "if \"sentiment\" in df.columns:\n",
        "    print(\"Number of classes:\", df[\"sentiment\"].nunique())\n",
        "    print(\"Classes:\", df[\"sentiment\"].unique())\n",
        "\n",
        "print(\"\\nEXAMPLE DATA ENTRIES\")\n",
        "print(df.head(10))\n",
        "\n",
        "file_size = os.path.getsize(file_path) / (1024 * 1024)\n",
        "print(\"\\nTotal dataset size: {:.2f} MB\".format(file_size))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1yBPcJfgPRe"
      },
      "source": [
        "### 3. DATA EXPLORATION & DISTRIBUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzfAbdR5f33q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Columns in dataset:\", df.columns)\n",
        "\n",
        "# Sentiment column name may differ; fix if needed\n",
        "sentiment_col = \"sentiment\" if \"sentiment\" in df.columns else \"airline_sentiment\" if \"airline_sentiment\" in df.columns else df.columns[1]\n",
        "\n",
        "print(\"Detected sentiment column:\", sentiment_col)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVAapxstgSdh"
      },
      "source": [
        "### 3.1 Classes Disribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4DVx_ZvgC0_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=df[sentiment_col])\n",
        "plt.title(\"Sentiment Class Distribution\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMKHQ9S3gkBO"
      },
      "source": [
        "### 3.2 Example texts per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J_PUL8UgHD3"
      },
      "outputs": [],
      "source": [
        "for label in df[sentiment_col].unique():\n",
        "    print(f\"EXAMPLE TWEETS FOR CLASS: {label}\")\n",
        "    print(df[df[sentiment_col] == label][\"text\"].head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oPbEPuhgr38"
      },
      "source": [
        "### 3.3 Tweet length distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgurl_Bwg14B"
      },
      "outputs": [],
      "source": [
        "# Ensure all text is string and handle missing values\n",
        "df['text'] = df['text'].astype(str)\n",
        "\n",
        "# Create 'text_length' column safely\n",
        "df['text_length'] = df['text'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
        "\n",
        "# Plot length distribution\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "sns.histplot(df['text_length'], bins=40, kde=True)\n",
        "plt.title(\"Tweet Length Distribution\")\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_5hAD6Dhvhp"
      },
      "source": [
        "### 4. DATA CLEANING & PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9tanYEMiBGK"
      },
      "outputs": [],
      "source": [
        "# 4. DATA CLEANING & PREPROCESSING\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemm = WordNetLemmatizer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZTjmcY7j_Mo"
      },
      "source": [
        "### 4.1 Cleaning Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY1dOybbj9hu"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()                                    # lowercasing\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)                  # remove URLs\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)                            # remove @mentions\n",
        "    text = re.sub(r\"#\\w+\", \"\", text)                            # remove hashtags\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)                     # remove special chars/numbers\n",
        "\n",
        "    tokens = text.split()                                       # tokenization\n",
        "    tokens = [w for w in tokens if w not in stop_words]         # stopword removal\n",
        "    tokens = [lemm.lemmatize(w) for w in tokens]                # lemmatization\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9GPdBs_kMbS"
      },
      "source": [
        "###4.2  Remove Duplicates & Missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfbqPgvfkIfs"
      },
      "outputs": [],
      "source": [
        "df[\"clean_text\"] = df[\"text\"].astype(str).apply(clean_text)\n",
        "\n",
        "# Remove empty rows\n",
        "df = df[df[\"clean_text\"].str.strip() != \"\"]\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(subset=[\"clean_text\"], inplace=True)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HusnHxJRkY8F"
      },
      "source": [
        "###4.3 Save Cleaned Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ngva3an2kXta"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"cleaned_tweets.csv\", index=False)\n",
        "print(\"Cleaned dataset saved as cleaned_tweets.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr80oJpjkwso"
      },
      "source": [
        "###5. Data Splitting:\n",
        "\n",
        "TRAIN / TEST / VALIDATION SPLIT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAdLRlvGky1N"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure dataset is shuffled\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Features (X) and Labels (y)\n",
        "X = df['clean_text']\n",
        "y = df[sentiment_col]  # detected sentiment column from before\n",
        "\n",
        "# 1. Split into training + temp (train = 70%, temp = 30%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Split temp into validation + test (val ≈ 10%, test ≈ 20%)\n",
        "# Since temp = 30% of total, we split temp as 1/3 val and 2/3 test\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Show dataset sizes\n",
        "print(\"Number of samples:\")\n",
        "print(\"Training set:\", len(X_train))\n",
        "print(\"Validation set:\", len(X_val))\n",
        "print(\"Testing set:\", len(X_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XFKUU-Tk7R8"
      },
      "source": [
        "### **`5.1 Explanation:`**\n",
        "\n",
        "\n",
        "We split the dataset into training, validation, and test sets to ensure that the model can learn effectively and be evaluated fairly.\n",
        "\n",
        "**Stratification** (stratify=y) ensures that each split maintains the same class distribution as the original dataset, preventing imbalance in any subset.\n",
        "\n",
        "**Reproducibility** (random_state=42) guarantees that the splits will be the same every time the code is run.\n",
        "\n",
        "Split ratios:\n",
        "\n",
        "**Training set ≈ 70%** of the data\n",
        "\n",
        "**Validation set ≈ 10%** of the data\n",
        "\n",
        "**Test set ≈ 20%** of the data\n",
        "\n",
        "***After splitting, the subsets are:***\n",
        "\n",
        "X_train, y_train → used for training the model\n",
        "\n",
        "X_val, y_val → used for tuning hyperparameters and early stopping\n",
        "\n",
        "X_test, y_test → used for evaluating final model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEA9qewfp2fu"
      },
      "source": [
        "### **6.Text Representation / Embedding :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbUIPaSFoW1I"
      },
      "outputs": [],
      "source": [
        "# Install transformers if not already installed\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "\n",
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load DistilBERT tokenizer and model\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "model.to(device)\n",
        "model.eval()  # set to evaluation mode\n",
        "\n",
        "# Function to get embeddings for a list of texts\n",
        "def get_embeddings(text_list, batch_size=32):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(text_list), batch_size):\n",
        "        batch_texts = text_list[i:i+batch_size]\n",
        "\n",
        "        # Tokenize batch\n",
        "        encoded_input = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        encoded_input = {k:v.to(device) for k,v in encoded_input.items()}\n",
        "\n",
        "        # Get model output\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encoded_input)\n",
        "            last_hidden_state = outputs.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "            # Mean pooling over the token dimension to get sentence embeddings\n",
        "            batch_embeddings = torch.mean(last_hidden_state, dim=1)\n",
        "            embeddings.append(batch_embeddings.cpu())\n",
        "\n",
        "    embeddings = torch.cat(embeddings, dim=0)\n",
        "    return embeddings\n",
        "\n",
        "# Example: generate embeddings for training, validation, and test sets\n",
        "X_train_embeddings = get_embeddings(X_train.tolist())\n",
        "X_val_embeddings   = get_embeddings(X_val.tolist())\n",
        "X_test_embeddings  = get_embeddings(X_test.tolist())\n",
        "\n",
        "print(\"Embeddings shape for training set:\", X_train_embeddings.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFZFwxXNo5-m"
      },
      "source": [
        "### **6.1 description of the Text Representation / Embedding step:**\n",
        "\n",
        "We convert text into numerical vectors to make it processable by machine learning models. For this project, we use DistilBERT, a transformer-based model that generates contextual embeddings, meaning each word’s representation depends on its surrounding words. This is especially useful for tweets, which are short, informal, and context-sensitive.\n",
        "\n",
        "Why DistilBERT:\n",
        "\n",
        "Captures context, sentiment nuances, and word meaning in different situations.\n",
        "\n",
        "Lighter and faster than full BERT while maintaining strong performance.\n",
        "\n",
        "Output:\n",
        "\n",
        "Each tweet is represented as a fixed-size 768-dimensional vector (after mean pooling), ready for model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioXgwFx8EK6M"
      },
      "source": [
        "##7. Train an Appropriate Neural Network–Based Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a78b6364"
      },
      "source": [
        "## Encode Labels\n",
        "\n",
        "### Subtask:\n",
        "Convert the categorical sentiment labels (y_train, y_val, y_test) into a numerical format, specifically one-hot encoding, which is required for training a neural network for multi-class classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb5cf453"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 2. Fit LabelEncoder on y_train\n",
        "label_encoder.fit(y_train)\n",
        "\n",
        "# 3. Transform y_train, y_val, y_test to numerical labels\n",
        "y_train_numerical = label_encoder.transform(y_train)\n",
        "y_val_numerical = label_encoder.transform(y_val)\n",
        "y_test_numerical = label_encoder.transform(y_test)\n",
        "\n",
        "# 4. Apply to_categorical for one-hot encoding\n",
        "y_train_encoded = to_categorical(y_train_numerical)\n",
        "y_val_encoded = to_categorical(y_val_numerical)\n",
        "y_test_encoded = to_categorical(y_test_numerical)\n",
        "\n",
        "# 5. Print shapes to confirm encoding dimensions\n",
        "print(\"Shape of y_train_encoded:\", y_train_encoded.shape)\n",
        "print(\"Shape of y_val_encoded:\", y_val_encoded.shape)\n",
        "print(\"Shape of y_test_encoded:\", y_test_encoded.shape)\n",
        "\n",
        "# Also print example of numerical and one-hot encoded labels\n",
        "print(\"\\nExample of y_train (first 5):\")\n",
        "print(y_train.head())\n",
        "print(\"\\nExample of y_train_numerical (first 5):\")\n",
        "print(y_train_numerical[:5])\n",
        "print(\"\\nExample of y_train_encoded (first 5):\")\n",
        "print(y_train_encoded[:5])\n",
        "\n",
        "# Store the number of classes for later use\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(f\"\\nNumber of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "206b2ca0"
      },
      "source": [
        "## Build and Compile the Neural Network Model\n",
        "\n",
        "### Subtask:\n",
        "Build a neural network model using TensorFlow/Keras, defining its architecture, and then compile it with an optimizer, loss function, and metrics.\n",
        "\n",
        "#### Instructions\n",
        "1.  Define a sequential Keras model.\n",
        "2.  Add an `InputLayer` with `input_shape=(X_train_embeddings.shape[1],)`. (The DistilBERT embeddings have 768 dimensions).\n",
        "3.  Add at least two `Dense` hidden layers with `ReLU` activation. Include `Dropout` layers after each hidden layer for regularization (e.g., `rate=0.3`).\n",
        "4.  Add a final `Dense` output layer with `num_classes` (the number of sentiment categories) units and `softmax` activation.\n",
        "5.  Compile the model using the `Adam` optimizer, `categorical_crossentropy` as the loss function, and `accuracy` as a metric.\n",
        "6.  Print the `model.summary()` to display the network architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cc01e84"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Dropout\n",
        "\n",
        "# 1. Define a sequential Keras model\n",
        "model = Sequential()\n",
        "\n",
        "# 2. Add an InputLayer\n",
        "model.add(InputLayer(input_shape=(X_train_embeddings.shape[1],)))\n",
        "\n",
        "# 3. Add at least two Dense hidden layers with ReLU activation and Dropout\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# 4. Add a final Dense output layer with num_classes units and softmax activation\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 6. Print the model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b383a11"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_embeddings,\n",
        "    y_train_encoded,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val_embeddings, y_val_encoded)\n",
        ")\n",
        "\n",
        "print(\"\\nModel training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a04eb65"
      },
      "source": [
        "**Reasoning**:\n",
        "The model has been trained, so the next logical step is to visualize its performance during training to understand how well it learned and generalized. This will involve plotting the accuracy and loss curves for both the training and validation datasets over the epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d960b5b9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dca725e"
      },
      "source": [
        "## Neural Network Model Summary\n",
        "\n",
        "**1. Neural Network Architecture:**\n",
        "*   **Type:** Sequential Model\n",
        "*   **Input Layer:** `InputLayer` with 768 dimensions (matching DistilBERT embedding size).\n",
        "*   **Hidden Layers:**\n",
        "    *   First Hidden Layer: `Dense` layer with 256 units and `ReLU` activation.\n",
        "    *   Dropout Layer: `Dropout` with a rate of 0.3 (after the first hidden layer for regularization).\n",
        "    *   Second Hidden Layer: `Dense` layer with 128 units and `ReLU` activation.\n",
        "    *   Dropout Layer: `Dropout` with a rate of 0.3 (after the second hidden layer for regularization).\n",
        "*   **Output Layer:** `Dense` layer with 3 units (corresponding to the number of sentiment classes) and `softmax` activation.\n",
        "\n",
        "**2. Training Hyperparameters:**\n",
        "*   **Optimizer:** `Adam` (an adaptive learning rate optimization algorithm).\n",
        "*   **Loss Function:** `categorical_crossentropy` (suitable for multi-class classification with one-hot encoded labels).\n",
        "*   **Metrics:** `accuracy`.\n",
        "*   **Batch Size:** 32 (number of samples per gradient update).\n",
        "*   **Epochs:** 10 (number of complete passes through the training dataset).\n",
        "\n",
        "**3. Observations from Training and Validation Curves:**\n",
        "\n",
        "*   **Accuracy:**\n",
        "    *   **Training Accuracy:** Shows a consistent increase over the epochs, starting around 55% and reaching approximately 70.45% by the final epoch. This indicates that the model is learning from the training data.\n",
        "    *   **Validation Accuracy:** Starts around 64.59% and generally improves, ending at approximately 68.58%. While it also increases, the gap between training and validation accuracy grows slightly, suggesting a minor degree of overfitting towards the later epochs. However, it appears to generalize reasonably well.\n",
        "\n",
        "*   **Loss:**\n",
        "    *   **Training Loss:** Decreases steadily from approximately 0.92 to 0.685, indicating that the model is reducing its error on the training data.\n",
        "    *   **Validation Loss:** Decreases initially from 0.7767 to 0.7292 but then shows some fluctuations and a slight increase towards the end, from epoch 8 (0.7328) to epoch 10 (0.7300), which further supports the observation of a slight overfitting, as the model's performance on unseen data plateaus or slightly degrades while training loss continues to fall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00d70e9a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Label Encoding:** Sentiment labels were successfully one-hot encoded into three categories, resulting in encoded label shapes of (number\\_of\\_samples, 3) for training, validation, and testing sets. For instance, `y_train_encoded` had a shape of (18764, 3).\n",
        "*   **Neural Network Architecture:**\n",
        "    *   The model utilized a sequential Keras architecture with a 768-dimensional `InputLayer`.\n",
        "    *   It included two `Dense` hidden layers (256 units and 128 units, both with ReLU activation), each followed by a `Dropout` layer with a rate of 0.3 for regularization.\n",
        "    *   The output layer was a `Dense` layer with 3 units and `softmax` activation, corresponding to the three sentiment classes.\n",
        "    *   The model comprised 230,147 trainable parameters.\n",
        "*   **Training Configuration:** The model was compiled with the `Adam` optimizer, `categorical_crossentropy` loss function, and `accuracy` as the evaluation metric. It was trained for 10 epochs with a batch size of 32.\n",
        "*   **Training Performance (over 10 epochs):**\n",
        "    *   **Training Accuracy:** Increased consistently from approximately 55.38% to 70.45%.\n",
        "    *   **Validation Accuracy:** Improved from 64.59% to 68.58%.\n",
        "    *   **Training Loss:** Decreased steadily from 0.9201 to 0.6849.\n",
        "    *   **Validation Loss:** Decreased initially from 0.7767 but showed slight fluctuations and a minor increase towards the end, stabilizing around 0.7300.\n",
        "*   **Observation of Overfitting:** The growing gap between training and validation accuracy, coupled with the stabilization or slight increase in validation loss while training loss continued to decrease, indicates a minor degree of overfitting towards the later epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oleDEYvwME9L"
      },
      "source": [
        "# 8. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0U8wabFMGAB"
      },
      "outputs": [],
      "source": [
        "# --- 8. Model Evaluation ---\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1) Predict on the test set\n",
        "y_pred_prob = model.predict(X_test_embeddings, batch_size=32)\n",
        "y_pred_idx = np.argmax(y_pred_prob, axis=1)\n",
        "y_true_idx = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# 2) Convert indices back to original labels\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_idx)\n",
        "y_true_labels = label_encoder.inverse_transform(y_true_idx)\n",
        "\n",
        "# 3) Compute evaluation metrics\n",
        "acc = accuracy_score(y_true_labels, y_pred_labels)\n",
        "print(\"Test Accuracy:\", acc)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_true_labels, y_pred_labels, digits=4))\n",
        "\n",
        "# 4) Confusion Matrix\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=label_encoder.classes_)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix on Test Set\")\n",
        "plt.show()\n",
        "\n",
        "# 5) Macro metrics (optional)\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "print(\"Precision (macro):\", precision_score(y_true_labels, y_pred_labels, average='macro'))\n",
        "print(\"Recall (macro):\", recall_score(y_true_labels, y_pred_labels, average='macro'))\n",
        "print(\"F1 (macro):\", f1_score(y_true_labels, y_pred_labels, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UzQ7cvCNLGS"
      },
      "source": [
        "### **9. Discussion & Reflection**\n",
        "A. Which representation and model performed best?\n",
        "\n",
        "We used DistilBERT to extract contextual embeddings (768 dimensions) and trained a simple neural network classifier (256 → 128 → softmax).\n",
        "Contextual embeddings generally outperform static embeddings such as Word2Vec or GloVe because they capture the meaning of a word based on its sentence context — especially important in short tweets.\n",
        "\n",
        "B. Performance observations\n",
        "\n",
        "The training accuracy was ~70% and the validation accuracy ~68%.\n",
        "This indicates good learning with slight overfitting.\n",
        "\n",
        "If the confusion matrix shows mixing between classes (e.g., neutral ↔ positive), this is expected because many tweets can be ambiguous or contain sarcasm.\n",
        "\n",
        "C. Challenges\n",
        "\n",
        "Slight class imbalance may affect accuracy.\n",
        "\n",
        "Informal language in tweets (slang, abbreviations, typos) makes classification harder.\n",
        "\n",
        "Removing hashtags/mentions/links helps cleaning but sometimes removes emotional cues.\n",
        "\n",
        "D. Improvements for better performance\n",
        "\n",
        "Fine-tuning DistilBERT or using BERT-base/RoBERTa.\n",
        "\n",
        "Data augmentation (back-translation, synonym substitution).\n",
        "\n",
        "Class weighting or focal loss for imbalance.\n",
        "\n",
        "Adding emoji/punctuation features.\n",
        "\n",
        "More epochs + learning rate scheduling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiqS73G-WNy-"
      },
      "source": [
        "### **10. (Hugging Face Integration)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGn54YToWkvC"
      },
      "source": [
        "Install and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNrXvXZuT2LG"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --upgrade\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngVRO06WoZU"
      },
      "source": [
        "### Load Local SST-2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c0fKizKT5Vs"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2U-tS4Wu70"
      },
      "source": [
        "### Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2lSIqTgT75_"
      },
      "outputs": [],
      "source": [
        "def predict_sst2(text):\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoding)\n",
        "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    # SST-2 labels:\n",
        "    # 1 = positive\n",
        "    # 0 = negative\n",
        "\n",
        "    if pred == 1:\n",
        "        return 4  # positive\n",
        "    else:\n",
        "        return 0  # negative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHwgwCC-W3lv"
      },
      "source": [
        "### Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjOmbE4dT-Hr"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "true_labels = y_test.tolist()\n",
        "\n",
        "for text in X_test.tolist():\n",
        "    preds.append(predict_sst2(text))\n",
        "\n",
        "preds = np.array(preds)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "accuracy = (preds == true_labels).mean()\n",
        "print(\"Local Transformer (SST-2) Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9eowbR2VMgC"
      },
      "outputs": [],
      "source": [
        "print(\"Unique labels in y_test:\", np.unique(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1V5NBGqVNcb"
      },
      "outputs": [],
      "source": [
        "test_samples = X_test[:10].tolist()\n",
        "for i, text in enumerate(test_samples):\n",
        "    print(i, \"Text:\", text)\n",
        "    print(\"Prediction:\", predict_sst2(text))\n",
        "    print(\"True label:\", y_test.iloc[i])\n",
        "    print(\"-----\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAedHKTJV-gw"
      },
      "source": [
        "Hugging Face Model Evaluation (Summary)\n",
        "\n",
        "In this step, we integrated a pretrained transformer model from Hugging Face,\n",
        "specifically DistilBERT fine-tuned on SST-2 sentiment classification.\n",
        "\n",
        "This model supports two classes only:\n",
        "\n",
        "Negative\n",
        "\n",
        "Positive\n",
        "\n",
        "However, our dataset contains three classes:\n",
        "\n",
        "Negative\n",
        "\n",
        "Neutral\n",
        "\n",
        "Positive\n",
        "\n",
        "Because the transformer model does not generate a “neutral” prediction, all\n",
        "neutral samples in the test set were automatically mismatched.\n",
        "This caused the overall accuracy to drop significantly, which explains the\n",
        "result we obtained:\n",
        "\n",
        "Accuracy = 0.0\n",
        "\n",
        "The purpose of this step was not to achieve high performance but to demonstrate\n",
        "how to integrate and evaluate a Hugging Face transformer model. Our results show\n",
        "a clear limitation: a model trained on a binary dataset (SST-2) cannot correctly\n",
        "handle a 3-class Twitter dataset.\n",
        "\n",
        "This difference in label space explains the low accuracy and highlights the\n",
        "importance of choosing a pretrained model that matches the target dataset’s\n",
        "class distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxOzkKzXlHgG"
      },
      "source": [
        "### Twitter Tweets Sentiment Analysis – Project Summary Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPDL9GyLlH1U"
      },
      "source": [
        "\n",
        "\n",
        "In this project we focused on performing sentiment analysis on a Kaggle Twitter dataset containing 27,481 tweets labeled as positive, neutral, or negative. After exploring the dataset, we observed a slight class imbalance and the typical short, informal nature of tweets. The text data underwent thorough preprocessing, including lowercasing, removing URLs and punctuation, eliminating stopwords, and applying lemmatization. The cleaned dataset was then split into training, validation, and test sets using stratified sampling to preserve label distribution.\n",
        "\n",
        "To represent text numerically, we used DistilBERT to generate 768-dimensional contextual embeddings for each tweet. These embeddings capture semantic meaning and sentiment-related context more effectively than traditional methods. A neural network classifier was built using these embeddings, consisting of two dense layers with dropout regularization and a softmax output layer. The model was trained for 10 epochs and achieved around 70% training accuracy and 68% validation accuracy, with mild signs of overfitting but overall good generalization.\n",
        "\n",
        "Evaluation on the test set included accuracy, precision, recall, F1-score, and a confusion matrix, showing that the model performed reasonably well but still struggled with neutral sentiment, which is inherently harder due to linguistic ambiguity. We also tested a Hugging Face model (DistilBERT fine-tuned on SST-2), but since it only supports two sentiment classes, it performed poorly on our three-class dataset, illustrating the importance of label compatibility.\n",
        "\n",
        "Overall, the project successfully demonstrated an end-to-end NLP workflow: dataset preparation, text cleaning, embedding generation using transformers, neural network training, evaluation, and comparison with a pretrained model. The approach shows strong potential, and performance could be further improved by fine-tuning a transformer directly on the dataset or applying advanced techniques for class balancing."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}